{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program builds the VGG16 convolutional neural network model for image classification. Once built the model is stored as car_v16.h5 file in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Config.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers \n",
    "#remove warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#import config file\n",
    "import import_ipynb\n",
    "import Config as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hni7kor\\AppData\\Local\\Continuum\\newanaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
    "base_model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (c.img_width, c.img_height, c.channels))\n",
    "# Freeze layer that do not need to be trained\n",
    "for layer in base_model.layers[:10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Model Block\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(c.num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your top layer block to your base model\n",
    "classifier = Model(base_model.input, predictions)\n",
    "#print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the CNN\n",
    "classifier.compile(optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 398 images belonging to 2 classes.\n",
      "Found 164 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
    "# To save augmentations un-comment save lines and add to your flow parameters.\n",
    "img_width, img_height = c.img_width, c.img_height\n",
    "train_data_dir = c.train_data_dir\n",
    "validation_data_dir = c.validation_data_dir\n",
    "batch_size = c.batch_size\n",
    "epochs = c.epoch\n",
    "num_classes = c.num_classes\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = c.train_rescale,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = c.train_zoom_range,\n",
    "width_shift_range = c.train_width_shift_range,\n",
    "height_shift_range=c.train_height_shift_range,\n",
    "rotation_range=c.train_rotation_range)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = c.test_rescale,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = c.test_zoom_range,\n",
    "width_shift_range = c.test_width_shift_range,\n",
    "height_shift_range=c.test_height_shift_range,\n",
    "rotation_range=c.test_rotation_range)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define when to stop training the model and then store the best model as car1.h5\n",
    "# This will be passed while fitting the model as callbacks methods.\n",
    "checkpoint = ModelCheckpoint(c.model_file, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "# Find the count for train and test images\n",
    "import os\n",
    "train_samples = 0\n",
    "validation_samples = 0\n",
    "\n",
    "cwd = os.getcwd()\n",
    "folder = c.train_data_dir\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    train_samples += len(files)\n",
    "\n",
    "\n",
    "folder = c.validation_data_dir\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    validation_samples += len(files)\n",
    "\n",
    "print(train_samples)\n",
    "print(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hni7kor\\AppData\\Local\\Continuum\\newanaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "398/398 [==============================] - 741s 2s/step - loss: 0.0928 - acc: 0.9632 - val_loss: 0.1048 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94880, saving model to car_v16.h5\n",
      "Epoch 2/10\n",
      "398/398 [==============================] - 766s 2s/step - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0966 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94880 to 0.95904, saving model to car_v16.h5\n",
      "Epoch 3/10\n",
      "398/398 [==============================] - 973s 2s/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0937 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95904 to 0.96192, saving model to car_v16.h5\n",
      "Epoch 4/10\n",
      "398/398 [==============================] - 695s 2s/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0918 - val_acc: 0.9653\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96192 to 0.96527, saving model to car_v16.h5\n",
      "Epoch 5/10\n",
      "398/398 [==============================] - 737s 2s/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0759 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96527 to 0.96950, saving model to car_v16.h5\n",
      "Epoch 6/10\n",
      "398/398 [==============================] - 716s 2s/step - loss: 0.0015 - acc: 0.9999 - val_loss: 0.0760 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.96950\n",
      "Epoch 7/10\n",
      "398/398 [==============================] - 721s 2s/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9642\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.96950\n",
      "Epoch 8/10\n",
      "398/398 [==============================] - 690s 2s/step - loss: 7.8857e-04 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.96950\n",
      "Epoch 9/10\n",
      "398/398 [==============================] - 705s 2s/step - loss: 7.6575e-04 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.96950\n",
      "Epoch 10/10\n",
      "398/398 [==============================] - 717s 2s/step - loss: 6.0950e-04 - acc: 1.0000 - val_loss: 0.0910 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.96950\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "history_object = classifier.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch = train_samples,\n",
    "epochs = c.epoch,\n",
    "callbacks = [checkpoint, early],\n",
    "validation_data = validation_generator,\n",
    "validation_steps = validation_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib inline\n",
    "# print(history_object.history.keys())\n",
    "# plt.plot(history_object.history['acc'])\n",
    "# plt.plot(history_object.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('acc')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history_object.history['loss'])\n",
    "# plt.plot(history_object.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
